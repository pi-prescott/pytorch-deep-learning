{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Steps with PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Cillian](https://cjber.github.io) suggested I check out [Aakash N.S.](https://www.linkedin.com/in/aakashns/?originalSubdomain=in)'s new PyTorch course. Which I did, and it looks great -- as does his [Jovian.ml platform for sharing Jupyter notebooks](https://jovian.ml). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The course is spread over six weeks, with weekly assignments. The first is to explore five functions from PyTorch's `.Tensor` class. So [here we go](https://www.youtube.com/watch?v=M0qSjLDVElY)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by importing the `torch` library and instantiating a `Tensor` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.Tensor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. GPU Computing with `.cuda()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the cool things about PyTorch is that it's set up for superfast GPU computing using NVIDIA's CUDA interface. The computer I have for my PhD research is CUDA enabled, but I haven't really had opportunity to make use of this fact yet. Let's check if CUDA is available on this machine..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, PyTorch just uses your CPU -- if you want it to use your GPU as its computing `device`, you need to say so explicitly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    t = t.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Making New Tensors with `.new_tensor()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you haven't heard of *tensors* before, you've probably still heard of *vectors* and *matrices*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2.], device='cuda:0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = t.new_tensor([1,2])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [2., 1.]], device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = t.new_tensor([\n",
    "    [1,2],\n",
    "    [2,1]\n",
    "])\n",
    "matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tensor is their generalization: a vector is tensor of *rank* (or dimensionality) 1; a matrix is a rank-2 tensor; and you can go on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rank of a vector is 1\n",
      "The rank of a matrix is 2\n"
     ]
    }
   ],
   "source": [
    "print(f'The rank of a vector is {vector.dim()}')\n",
    "print(f'The rank of a matrix is {matrix.dim()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And what we think of as 'ordinary numbers' are tensors of rank zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3., device='cuda:0')\n",
      "The rank of a scalar is 0\n"
     ]
    }
   ],
   "source": [
    "scalar = t.new_tensor(3)\n",
    "print(scalar)\n",
    "print(f'The rank of a scalar is {scalar.dim()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch also allows us to quickly generate a new tensor that is full of zeros, ones, or whatever number we like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros = t.new_zeros((10,10))\n",
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.]], device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones = t.new_ones((5,5))\n",
    "ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[17., 17., 17., 17., 17.],\n",
       "        [17., 17., 17., 17., 17.],\n",
       "        [17., 17., 17., 17., 17.],\n",
       "        [17., 17., 17., 17., 17.],\n",
       "        [17., 17., 17., 17., 17.],\n",
       "        [17., 17., 17., 17., 17.],\n",
       "        [17., 17., 17., 17., 17.],\n",
       "        [17., 17., 17., 17., 17.]], device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anything = t.new_full((8,5),17)\n",
    "anything"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can generate a random array of whatever shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4485, 0.1529, 0.7111],\n",
       "        [0.3065, 0.3602, 0.1230],\n",
       "        [0.9874, 0.7289, 0.0033]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random = torch.rand(3,3)\n",
    "random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Matrix Multiplicatoin with `.matmul()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch lets us do matrix multiplication with `.matmul()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 4.],\n",
       "        [4., 5.]], device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.matmul(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5., 4.], device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.matmul(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, this doesn't work quite how I expected -- PyTorch will transpose a one-dimensional vector as necessary to give a dot product (ie. an inner product)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5., device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.matmul(vector.T) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5., device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.matmul(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5., device='cuda:0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.T.matmul(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5., device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.T.matmul(vector.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you do want the outer product, you can use `.ger()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [2., 4.]], device='cuda:0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.ger(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Finding the Inverse with `.inverse()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch makes it trivial to get the inverse of a tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3333,  0.6667],\n",
       "        [ 0.6667, -0.3333]], device='cuda:0')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.inverse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check whether this inverse does actually work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0.],\n",
       "        [0., 1.]], device='cuda:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix @ matrix.inverse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Easy Eigenvalues with `.eig()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And it's similarly easy to find a tensor's eigenvalues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.eig(\n",
       "eigenvalues=tensor([[ 3.0000,  0.0000],\n",
       "        [-1.0000,  0.0000]], device='cuda:0'),\n",
       "eigenvectors=tensor([], device='cuda:0'))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.eig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you also want the eigenvectors, then just say so when you run the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.eig(\n",
       "eigenvalues=tensor([[ 3.0000,  0.0000],\n",
       "        [-1.0000,  0.0000]], device='cuda:0'),\n",
       "eigenvectors=tensor([[ 0.7071, -0.7071],\n",
       "        [ 0.7071,  0.7071]], device='cuda:0'))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.eig(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing PyTorch with GPU to Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use those simple functions to generate a big tensor and see how quickly PyTorch can find its eigenvalues compared to Numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_x = 10**3\n",
    "dim_y = 10**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0745,  0.2748, -1.4848,  ..., -0.9740,  0.6911,  0.8833],\n",
       "        [ 0.5165, -0.3985,  0.7268,  ...,  2.3921, -0.5628,  0.1531],\n",
       "        [-0.3024,  1.2555, -1.5737,  ..., -0.9724, -1.0857, -1.1055],\n",
       "        ...,\n",
       "        [ 1.8176, -0.3609, -0.8389,  ..., -0.7773, -2.0532,  0.6860],\n",
       "        [ 0.6077, -1.1111, -0.0602,  ..., -0.1695, -0.2805,  1.6845],\n",
       "        [ 0.2828,  0.4366, -1.0544,  ...,  0.2385,  0.4885, -1.2533]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "massive = torch.randn((dim_x,dim_y)).cuda()\n",
    "massive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0744525 ,  0.27476978, -1.4848366 , ..., -0.9740233 ,\n",
       "         0.69107497,  0.88326013],\n",
       "       [ 0.5165413 , -0.39849052,  0.7268396 , ...,  2.392065  ,\n",
       "        -0.56276095,  0.15305625],\n",
       "       [-0.30239376,  1.255493  , -1.5737166 , ..., -0.97236514,\n",
       "        -1.0857061 , -1.1054957 ],\n",
       "       ...,\n",
       "       [ 1.8176234 , -0.3608592 , -0.83891994, ..., -0.7772828 ,\n",
       "        -2.0532408 ,  0.68600905],\n",
       "       [ 0.6076961 , -1.111058  , -0.06023345, ..., -0.16951588,\n",
       "        -0.28046852,  1.6844993 ],\n",
       "       [ 0.2827644 ,  0.43656364, -1.054425  , ...,  0.23848584,\n",
       "         0.48854375, -1.2532959 ]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_version = massive.cpu().numpy()\n",
    "numpy_version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use Jupyter's `%time` magic..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 2 µs, total: 5 µs\n",
      "Wall time: 14.8 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "pytorch_eigs = massive.eig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 45 µs, sys: 14 µs, total: 59 µs\n",
      "Wall time: 10 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "numpy_eigs = np.linalg.eig(numpy_version)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use `jovian.commit()` to share this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, I've left this until the last minute, and the deadline for this assignment approaches, so I should finish."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As our final step, we'll import the `jovian` library and commit this, so that the world can see it as [Jovian.ml](https://jovian.ml)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "if (window.IPython && IPython.notebook.kernel) IPython.notebook.kernel.execute('jovian.utils.jupyter.get_notebook_name_saved = lambda: \"' + IPython.notebook.notebook_name + '\"')"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Attempting to save notebook..\u001b[0m\n",
      "[jovian] Updating notebook \"peterprescott/pytorch-first-steps\" on https://jovian.ai/\u001b[0m\n",
      "[jovian] Uploading notebook..\u001b[0m\n",
      "[jovian] Capturing environment..\u001b[0m\n",
      "[jovian] Committed successfully! https://jovian.ai/peterprescott/pytorch-first-steps\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://jovian.ai/peterprescott/pytorch-first-steps'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jovian\n",
    "jovian.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Attempting to save notebook..\u001b[0m\n",
      "[jovian] Updating notebook \"peterprescott/pytorch-first-steps\" on https://jovian.ai/\u001b[0m\n",
      "[jovian] Uploading notebook..\u001b[0m\n",
      "[jovian] Capturing environment..\u001b[0m\n",
      "[jovian] Committed successfully! https://jovian.ai/peterprescott/pytorch-first-steps\u001b[0m\n",
      "[jovian] Submitting assignment..\u001b[0m\n",
      "[jovian] Verify your submission at https://jovian.ai/learn/deep-learning-with-pytorch-zero-to-gans/assignment/assignment-1-all-about-torch-tensor\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "jovian.submit(assignment='zerotogans-a1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
